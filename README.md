# Задча для отбора на кафедру КИС

## 1. Выбор датасета.

Мне хотелось, чтобы датасет был хорошо собран и достаточно понятно описан. Кроме того, важен размер: на совсем маленькой выборке тяжело работать. После просмотра нескольких наборов данных на платформе kaggle, я остановился на этом наборе данных: https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews/code

## 2. Exploratory Data Analysis (EDA).

Все подробности можно посмотреть в ноутбуке; самое важное, что я узнал - это то, что классы (0 - негативная фраза, 1 - частично негативная, 2 - нейтральная, 3 - частично позитивная, 4 - позитивная) не одинаковые по размеру, что важно при выборе функции ошибки и дальнейшей работе с датасетом.

![image](https://user-images.githubusercontent.com/50750489/160660061-564e2cb8-b42c-4c08-88fc-84d2396f2766.png)

Т.е. примерно половина всех комментариев в обучающем наборе - нейтральные.

После этого я построил распределения в зависимости от длины фразы.

![image](https://user-images.githubusercontent.com/50750489/160660909-8e0884ee-6b79-4971-88ad-4058af12acb3.png)

Стало понятно, что большинство фраз не очень длинные, и что самое важное - многие из них - артикли, длина артиклей - 1 или 2 символа (a или an). Конечно, это выброс, от которого надо избавиться.

## 3. Предобработка датасета.

Что было сделано?

- все буквы переведены в маленькие (str.lower())
- были убраны все знаки препинания
- предложения разделены на слова пробелами (превращены в токены, tokenize)
- удалены стоп-слова (stopwords): слова, которые не несут никакой эмоциональной окраски (и зачастую смысловой), которые усложняют задачу модели
- проведена лемматизация (приведение к общей форме слова)
- сгруппированы однокоренные слова через SnowballStemming (считается, что он лучше PorterStemming)
- слова были переведены в tf-idf статистику (на этом моменте гугл колаб заполнил всю память, поэтому пришлось немного подсократить датасет)


## 4. Модель

Моделью был выбран случайный лес, потому что в аналогичных работах в классификации комментариев на YouTube (и других статьях, например, https://arxiv.org/ftp/arxiv/papers/2101/2101.06353.pdf) показано, что для задачи text sentiment analysis с учётом выбранных мной методов feature extraction (в частности, tf-idf) точность таких моделей может достигать 82% и выше, что по моему мнению хороший результат. При этом модель не такая сложная, так что было интересно попробовать повторить полученный результат на выбранном датасете.

## 5. Что дальше? 

Хотелось бы:
- Поработать с гиперпараметрами у модели. Возможно, сделать сетку поиска лучших.
- Попробовать другие модели для задачи
- Обработать весь датасет, а не часть, т.к. ОЗУ закончилась.
